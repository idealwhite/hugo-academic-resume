---
title: Semi-supervised Visual Feature Integration for Language Models through
  Sentence Visualization
publication_types:
  - "1"
authors:
  - Lisai Zhang
  - Qingcai Chen
  - Joanna Siebert
  - Buzhou Tang
doi: "3462244.3479965"
publication: International Conference on Multimodal Interaction, 2021
publication_short: ""
abstract: "Integrating visual features has been proved useful for natural
  language understanding tasks. Nevertheless, most existing multimodal language
  models highly rely on training on aligned image and text data. In this paper,
  we propose a novel semi-supervised visual integration framework for
  pre-trained language models. In the framework, the visual features are
  obtained through a sentence visualization and vision-language fusion
  mechanism. The uniqueness includes: 1) the integration is conducted via a
  semi-supervised framework and does not require aligned images for the
  processed sentences. 2) the framework works as an auxiliary component, and
  will not affect the language processing ability of the integrated language
  model. Experimental results on both natural language inference and reading
  comprehension tasks demonstrate that our framework improves the strong
  baseline language models. Considering that our framework only requires an
  image database, and does not require aligned images for the processed texts,
  it provides a feasible way for multimodal language learning."
draft: false
featured: false
projects:
  - Natural Science Foundation of China
  - Grant No.61872113
image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
date: 2021-10-18T02:36:36.933Z
---
